{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSMARCO Document Ranking Task using PyTerrier - uogTrBaseDPHQ\n",
    "\n",
    "This notebook demonstrates indexing and performing a baseline DPH + Query Expansion run for the MSMARCO Document Ranking task using [PyTerrier](https://github.com/terrier-org/pyterrier).\n",
    "\n",
    "Author: Craig Macdonald, University of Glasgow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTerrier Setup\n",
    "\n",
    "We need to install PyTerrier. We can do this using Pip by uncommenting this line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-31T17:17:40.424000Z",
     "iopub.status.busy": "2020-08-31T17:17:40.423534Z",
     "iopub.status.idle": "2020-08-31T17:17:40.429263Z",
     "shell.execute_reply": "2020-08-31T17:17:40.428014Z",
     "shell.execute_reply.started": "2020-08-31T17:17:40.423920Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade git+https://github.com/terrier-org/pyterrier.git#egg=python-terrier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your JAVA_HOME environment variable does not specify a directory for Java 11, you should set it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-31T17:17:40.431704Z",
     "iopub.status.busy": "2020-08-31T17:17:40.431221Z",
     "iopub.status.idle": "2020-08-31T17:17:40.443326Z",
     "shell.execute_reply": "2020-08-31T17:17:40.442354Z",
     "shell.execute_reply.started": "2020-08-31T17:17:40.431588Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/local/trmaster/opt/jdk-11.0.6/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now start PyTerrier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-31T17:17:40.445851Z",
     "iopub.status.busy": "2020-08-31T17:17:40.445372Z",
     "iopub.status.idle": "2020-08-31T17:17:42.489403Z",
     "shell.execute_reply": "2020-08-31T17:17:42.488299Z",
     "shell.execute_reply.started": "2020-08-31T17:17:40.445688Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "if not pt.started():\n",
    "  pt.init(mem=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Setup\n",
    "\n",
    "PyTerrier contains a Datasets API that alllows to index/retrieve from a number of standard datasets. We can see which datasets are supported using `pt.list_datasets()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-31T17:17:42.491335Z",
     "iopub.status.busy": "2020-08-31T17:17:42.491077Z",
     "iopub.status.idle": "2020-08-31T17:17:42.527357Z",
     "shell.execute_reply": "2020-08-31T17:17:42.526598Z",
     "shell.execute_reply.started": "2020-08-31T17:17:42.491289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>topics</th>\n",
       "      <th>qrels</th>\n",
       "      <th>corpus</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50pct</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vaswani</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trec-deep-learning-docs</td>\n",
       "      <td>(train, dev, test, test-2020, leaderboard-2020)</td>\n",
       "      <td>(train, dev, test)</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trec-robust-2004</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trec-robust-2005</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>trec-covid</td>\n",
       "      <td>(round1, round2, round3)</td>\n",
       "      <td>(round1, round2)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>trec-wt2g</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>trec-wt-2002</td>\n",
       "      <td>(td, np)</td>\n",
       "      <td>(np, td)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>trec-wt-2003</td>\n",
       "      <td>(td, np)</td>\n",
       "      <td>(np, td)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>trec-wt-2004</td>\n",
       "      <td>(all, np, hp, td)</td>\n",
       "      <td>(hp, td, np, all)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>trec-wt-2009</td>\n",
       "      <td>True</td>\n",
       "      <td>(adhoc, adhoc.catA, adhoc.catB)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>trec-wt-2010</td>\n",
       "      <td>True</td>\n",
       "      <td>(adhoc)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>trec-wt-2011</td>\n",
       "      <td>True</td>\n",
       "      <td>(adhoc)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>trec-wt-2012</td>\n",
       "      <td>True</td>\n",
       "      <td>(adhoc)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    dataset                                           topics  \\\n",
       "0                     50pct                                             None   \n",
       "1                   vaswani                                             True   \n",
       "2   trec-deep-learning-docs  (train, dev, test, test-2020, leaderboard-2020)   \n",
       "3          trec-robust-2004                                             True   \n",
       "4          trec-robust-2005                                             True   \n",
       "5                trec-covid                         (round1, round2, round3)   \n",
       "6                 trec-wt2g                                             True   \n",
       "7              trec-wt-2002                                         (td, np)   \n",
       "8              trec-wt-2003                                         (td, np)   \n",
       "9              trec-wt-2004                                (all, np, hp, td)   \n",
       "10             trec-wt-2009                                             True   \n",
       "11             trec-wt-2010                                             True   \n",
       "12             trec-wt-2011                                             True   \n",
       "13             trec-wt-2012                                             True   \n",
       "\n",
       "                              qrels corpus index  \n",
       "0                              None   None  True  \n",
       "1                              True   True  True  \n",
       "2                (train, dev, test)   True  None  \n",
       "3                              True   None  None  \n",
       "4                              True   None  None  \n",
       "5                  (round1, round2)   None  None  \n",
       "6                              True   None  None  \n",
       "7                          (np, td)   None  None  \n",
       "8                          (np, td)   None  None  \n",
       "9                 (hp, td, np, all)   None  None  \n",
       "10  (adhoc, adhoc.catA, adhoc.catB)   None  None  \n",
       "11                          (adhoc)   None  None  \n",
       "12                          (adhoc)   None  None  \n",
       "13                          (adhoc)   None  None  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.list_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the MSMARCO document ranking task, the corresponding dataset is `\"trec-deep-learning-docs\"`, which we can see provides various topics and qrels sets, and provides a copy of the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-31T17:17:42.528811Z",
     "iopub.status.busy": "2020-08-31T17:17:42.528432Z",
     "iopub.status.idle": "2020-08-31T17:17:42.532236Z",
     "shell.execute_reply": "2020-08-31T17:17:42.531499Z",
     "shell.execute_reply.started": "2020-08-31T17:17:42.528643Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = pt.get_dataset(\"trec-deep-learning-docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run `get_corpus()`, it will download the TREC formatted version of the corpus. NB: This is 22GB, so too much for Google Colab unfortunately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-31T17:17:42.533447Z",
     "iopub.status.busy": "2020-08-31T17:17:42.533206Z",
     "iopub.status.idle": "2020-08-31T17:17:42.543801Z",
     "shell.execute_reply": "2020-08-31T17:17:42.542954Z",
     "shell.execute_reply.started": "2020-08-31T17:17:42.533402Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/users/craigm/.pyterrier/corpora/trec-deep-learning-docs/corpus/msmarco-docs.trec.gz']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_corpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing\n",
    "\n",
    "Lets get setup for indexing. This is a basic configuration, without applying any stopword removal or stremming. Indexing on our machine took just over 1 hour using a single thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-31T17:17:42.545078Z",
     "iopub.status.busy": "2020-08-31T17:17:42.544818Z",
     "iopub.status.idle": "2020-08-31T17:17:42.553766Z",
     "shell.execute_reply": "2020-08-31T17:17:42.552873Z",
     "shell.execute_reply.started": "2020-08-31T17:17:42.545032Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./index/data.properties\"):\n",
    "\n",
    "    !mkdir -p index\n",
    "    props = {\n",
    "      'indexer.meta.reverse.keys':'docno',\n",
    "      'termpipelines' : '',\n",
    "    }\n",
    "\n",
    "    pt.logging('INFO')\n",
    "    indexer = pt.TRECCollectionIndexer(\"./index\")\n",
    "    indexer.setProperties(**props)\n",
    "    indexref = indexer.index(dataset.get_corpus())\n",
    "    \n",
    "else:\n",
    "    indexref = pt.IndexRef.of(\"./index/data.properties\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see the statistics of the generated index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-31T17:17:42.555758Z",
     "iopub.status.busy": "2020-08-31T17:17:42.555477Z",
     "iopub.status.idle": "2020-08-31T17:17:43.379318Z",
     "shell.execute_reply": "2020-08-31T17:17:43.378327Z",
     "shell.execute_reply.started": "2020-08-31T17:17:42.555713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 3213835\n",
      "Number of terms: 17470544\n",
      "Number of fields: 0\n",
      "Number of tokens: 3667907097\n",
      "Field names: []\n",
      "Positions:   false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pt.logging('WARN')\n",
    "index = pt.IndexFactory.of(indexref)\n",
    "print(index.getCollectionStatistics().toString())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All being well, you should have indexed 3213835 documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval\n",
    "\n",
    "This notebook contains a demonstration of how to execute a baseline retrieval run, using a Divergence from Randomness weighting model called [DPH](http://terrier.org/docs/current/javadoc/org/terrier/matching/models/DPH.html) and the Bo1 query expansion model.\n",
    "\n",
    "We use an object called BatchRetrieve. The constructor parameters are as follows:\n",
    " - `wmodel` - name of the Terrier weighting model class\n",
    " - `control` - Retrieval configuration - here we specify the query expansion configuration\n",
    " - `properties` - Terrier global configuration - here we re-specify the termpipeline to match the indexing configuration\n",
    " - `verbose` - we set this to True, so we can view progress (using [TQDM](https://github.com/tqdm/tqdm)) when retrieving for these large topic sets.\n",
    " \n",
    "Finally, we only want 100 results per query, so we apply the rank cutoff operator `%`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-01T00:38:03.428365Z",
     "iopub.status.busy": "2020-09-01T00:38:03.428140Z",
     "iopub.status.idle": "2020-09-01T00:38:03.434194Z",
     "shell.execute_reply": "2020-09-01T00:38:03.433550Z",
     "shell.execute_reply.started": "2020-09-01T00:38:03.428328Z"
    }
   },
   "outputs": [],
   "source": [
    "DPH_br_qe = pt.BatchRetrieve(index, \n",
    "                             wmodel=\"DPH\", \n",
    "                             controls={\"qe\" : \"on\", \"qemodel\" : \"Bo1\"}, \n",
    "                             properties={\"termpipelines\": \"\"}, \n",
    "                             verbose=True) % 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now evaluate performance on the MSMARCO Dev set. Experiment is a declarative notation for running one or more experiment pipelines on a standard set of topics, then evaluating them for the same qrels. We report the MRR measure.\n",
    "\n",
    "The dev set is quite large (> 5000 queries). This took abuot 2-3 hours to run for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-31T17:17:43.396093Z",
     "iopub.status.busy": "2020-08-31T17:17:43.395881Z",
     "iopub.status.idle": "2020-08-31T19:31:34.003433Z",
     "shell.execute_reply": "2020-08-31T19:31:34.002703Z",
     "shell.execute_reply.started": "2020-08-31T17:17:43.396059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:17:43.409 [main] WARN  o.t.a.batchquerying.TRECQuery - trec.encoding is not set; resorting to platform default (ISO-8859-1). Retrieval may be platform dependent. Recommend trec.encoding=UTF-8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5193/5193 [2:13:43<00:00,  1.55s/q]  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>recip_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RankCutoff(BR(DPH), 100)</td>\n",
       "      <td>0.248632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  recip_rank\n",
       "0  RankCutoff(BR(DPH), 100)    0.248632"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment([DPH_br_qe], dataset.get_topics(\"dev\"), dataset.get_qrels(\"dev\"), eval_metrics=[\"recip_rank\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Leaderboard results\n",
    "\n",
    "Finally, lets prepare a results file for sending to the leaderboard. Again, with 5793 topics, this took about 2-3 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-01T00:38:03.435373Z",
     "iopub.status.busy": "2020-09-01T00:38:03.435113Z",
     "iopub.status.idle": "2020-09-01T03:18:06.655907Z",
     "shell.execute_reply": "2020-09-01T03:18:06.654849Z",
     "shell.execute_reply.started": "2020-09-01T00:38:03.435314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:38:03.439 [main] WARN  o.t.a.batchquerying.TRECQuery - trec.encoding is not set; resorting to platform default (ISO-8859-1). Retrieval may be platform dependent. Recommend trec.encoding=UTF-8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5793/5793 [2:39:48<00:00,  1.66s/q]  \n"
     ]
    }
   ],
   "source": [
    "pt.io.write_results(DPH_br_qe(dataset.get_topics(\"leaderboard-2020\")), \"uogTrBaseDPHQ.res.gz\", format=\"minimal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyterrier",
   "language": "python",
   "name": "pyterrier"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
